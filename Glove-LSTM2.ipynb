{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28f38a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87d2e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('preprocessed_lyrics.csv')\n",
    "\n",
    "df = df.groupby('Genre', group_keys=False).apply(lambda s: s.sample(3333, random_state=42)) #\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d54fbe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "labels = label_encoder.fit_transform(df.Genre.values)\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222df10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(df.Lyric.values, \n",
    "                                                labels, \n",
    "                                                stratify=labels, \n",
    "                                                random_state=42, \n",
    "                                                test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c51cc0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400001it [00:10, 38733.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {} # Will be a 100dim vector for each word in glove, found as embeddings_index[word]\n",
    "f = open('glove.6B.100d.txt',encoding='utf8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdeabc",
   "metadata": {},
   "source": [
    "## Defining hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8744b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = 30000\n",
    "MAX_LENGTH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3cb62f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(list(xtrain) + list(xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271ab1e",
   "metadata": {},
   "source": [
    "Turning tokens into lists of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54ac9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_sequence = tokenizer.texts_to_sequences(xtrain)\n",
    "xtest_sequence = tokenizer.texts_to_sequences(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35168ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 500)\n"
     ]
    }
   ],
   "source": [
    "xtrain_padding = sequence.pad_sequences(xtrain_sequence, maxlen=MAX_LENGTH)\n",
    "xtest_padding = sequence.pad_sequences(xtest_sequence, maxlen=MAX_LENGTH)\n",
    "print(xtest_padding.shape)\n",
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fd4040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29633/29633 [00:00<00:00, 508330.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29634, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "print(embedding_matrix.shape)\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001bcbe4",
   "metadata": {},
   "source": [
    "- Embedding_matrix is now just a matrix over the embeddings. i.e as embedding_index but in matrix form with 29000 ish rows\n",
    "- word_index is a mapping of all of the words appearing in lyrics to an integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5b993",
   "metadata": {},
   "source": [
    "## LSTM model with glove embeddings and two dense layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa50c82",
   "metadata": {},
   "source": [
    "We could change dropout percentage to further avoid/less avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d741a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                    100,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=MAX_LENGTH,\n",
    "                    trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c1d5d",
   "metadata": {},
   "source": [
    "### binarize the labels for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c3aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(df['label'])\n",
    "x = list(df['Lyric'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.np_utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    print(one_hot)\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "\n",
    "x_enc = x\n",
    "y_enc = encode(le, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_encode = np_utils.to_categorical(ytrain)\n",
    "ytest_encode = np_utils.to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d6a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(xtrain_padding, \n",
    "                    y=ytrain_encode, \n",
    "                    batch_size=512, \n",
    "                    epochs=1, \n",
    "                    verbose=1, \n",
    "    predicts = model.predict(x_test, batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dd643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_preds))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy of ELMO is:\",accuracy_score(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_plots(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[‘val_’+string])\n",
    "    plt.xlabel(“Epochs”)\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, ‘val_’+string])\n",
    "    plt.show()\n",
    "\n",
    "graph_plots(history, “accuracy”)\n",
    "graph_plots(history, “loss”)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
