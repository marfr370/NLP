{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f38a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d2e3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SName</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Artist</th>\n",
       "      <th>lyric_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76674</th>\n",
       "      <td>Naked</td>\n",
       "      <td>You got a girl. That doesn't look a thing like...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15016</th>\n",
       "      <td>Chemical Prisoner</td>\n",
       "      <td>I walk a fine line between coping and insanity...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Falling In Reverse</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82431</th>\n",
       "      <td>Broken</td>\n",
       "      <td>I wear the red shoes with the holes. And to re...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92219</th>\n",
       "      <td>Look What You Made Me Do</td>\n",
       "      <td>I don't like your little games. Don't like you...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>Something's Gotta Give</td>\n",
       "      <td>I woke up in a strangers bed. With pins and ne...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>All Time Low</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33411</th>\n",
       "      <td>Nude</td>\n",
       "      <td>Don't get any big ideas. They're not gonna hap...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Radiohead</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81697</th>\n",
       "      <td>The London Bridge Song</td>\n",
       "      <td>Joni's lighthearted take on \"London Bridge\". w...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Joni Mitchell</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40963</th>\n",
       "      <td>Pilgrim</td>\n",
       "      <td>I am just a pilgrim on this road, boys. This a...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Steve Earle</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58966</th>\n",
       "      <td>Camera Ready</td>\n",
       "      <td>Its the crazy mane. wit the crazy change. got ...</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>Gucci Mane</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70228</th>\n",
       "      <td>I Can do Better</td>\n",
       "      <td>Uh!. Yeah, you can do it. Ha, heh heh. I could...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          SName  \\\n",
       "76674                     Naked   \n",
       "15016         Chemical Prisoner   \n",
       "82431                    Broken   \n",
       "92219  Look What You Made Me Do   \n",
       "1955     Something's Gotta Give   \n",
       "...                         ...   \n",
       "33411                      Nude   \n",
       "81697    The London Bridge Song   \n",
       "40963                   Pilgrim   \n",
       "58966              Camera Ready   \n",
       "70228           I Can do Better   \n",
       "\n",
       "                                                   Lyric    Genre  \\\n",
       "76674  You got a girl. That doesn't look a thing like...      Pop   \n",
       "15016  I walk a fine line between coping and insanity...     Rock   \n",
       "82431  I wear the red shoes with the holes. And to re...      Pop   \n",
       "92219  I don't like your little games. Don't like you...      Pop   \n",
       "1955   I woke up in a strangers bed. With pins and ne...     Rock   \n",
       "...                                                  ...      ...   \n",
       "33411  Don't get any big ideas. They're not gonna hap...     Rock   \n",
       "81697  Joni's lighthearted take on \"London Bridge\". w...      Pop   \n",
       "40963  I am just a pilgrim on this road, boys. This a...     Rock   \n",
       "58966  Its the crazy mane. wit the crazy change. got ...  Hip Hop   \n",
       "70228  Uh!. Yeah, you can do it. Ha, heh heh. I could...     Rock   \n",
       "\n",
       "                   Artist  lyric_length  \n",
       "76674    Enrique Iglesias           443  \n",
       "15016  Falling In Reverse           200  \n",
       "82431          Katy Perry           381  \n",
       "92219        Taylor Swift           517  \n",
       "1955         All Time Low           231  \n",
       "...                   ...           ...  \n",
       "33411           Radiohead            64  \n",
       "81697       Joni Mitchell           358  \n",
       "40963         Steve Earle            92  \n",
       "58966          Gucci Mane           437  \n",
       "70228       Avril Lavigne           422  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('processed_lyrics.csv')\n",
    "\n",
    "\n",
    "subset = df.sample(n=1000)\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54fbe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "labels = label_encoder.fit_transform(subset.Genre.values)\n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "222df10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(subset.Lyric.values, \n",
    "                                                labels, \n",
    "                                                stratify=labels, \n",
    "                                                random_state=42, \n",
    "                                                test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51cc0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400001it [00:07, 54549.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove/glove.6B.100d.txt',encoding='utf8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdeabc",
   "metadata": {},
   "source": [
    "## Defining hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968d83ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8744b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = 2000\n",
    "MAX_LENGTH = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3cb62f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(list(xtrain) + list(xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271ab1e",
   "metadata": {},
   "source": [
    "Turning tokens into lists of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ac9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_sequence = tokenizer.texts_to_sequences(xtrain)\n",
    "xtest_sequence = tokenizer.texts_to_sequences(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35168ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_padding = sequence.pad_sequences(xtrain_sequence, maxlen=MAX_LENGTH)\n",
    "xtest_padding = sequence.pad_sequences(xtest_sequence, maxlen=MAX_LENGTH)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fd4040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 13284/13284 [00:00<00:00, 546417.84it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5b993",
   "metadata": {},
   "source": [
    "## LSTM model with glove embeddings and two dense layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa50c82",
   "metadata": {},
   "source": [
    "We could change dropout percentage to further avoid/less avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d741a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 20:29:59.958872: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                    100,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=MAX_LENGTH,\n",
    "                    trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c1d5d",
   "metadata": {},
   "source": [
    "### binarize the labels for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14e1b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_encode = np_utils.to_categorical(ytrain)\n",
    "ytest_encode = np_utils.to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d6a4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 1s/step - loss: 1.1191 - accuracy: 0.4144 - val_loss: 0.9850 - val_accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain_padding, \n",
    "                    y=ytrain_encode, \n",
    "                    batch_size=512, \n",
    "                    epochs=1, \n",
    "                    verbose=1, \n",
    "                    validation_data=(xtest_padding, ytest_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_plots(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[‘val_’+string])\n",
    "    plt.xlabel(“Epochs”)\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, ‘val_’+string])\n",
    "    plt.show()\n",
    "\n",
    "graph_plots(history, “accuracy”)\n",
    "graph_plots(history, “loss”)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP]",
   "language": "python",
   "name": "conda-env-NLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
