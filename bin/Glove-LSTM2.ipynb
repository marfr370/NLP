{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f38a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d2e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('preprocessed_lyrics.csv')\n",
    "\n",
    "df = df.groupby('Genre', group_keys=False).apply(lambda s: s.sample(333, random_state=42)) #\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43738674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SName</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Artist</th>\n",
       "      <th>lyric_length_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>Number One</td>\n",
       "      <td>uh uh uh I got to bring dirty thas you well wa...</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>Nelly</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>Put That Thang On U (ft. Snoop Dogg)</td>\n",
       "      <td>Fala lady like lady Ne Yo sing to real quick I...</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>Ne-yo</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9164</th>\n",
       "      <td>The Resurrection of Scott Mescudi</td>\n",
       "      <td>Instrumental once realize free you fly</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>Kid Cudi</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>Feel Like Home</td>\n",
       "      <td>these day dark night cold People act like lose...</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>Fort Minor</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>Public Service Announcement 2000</td>\n",
       "      <td>this another public bring in by Slim Shady Emi...</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31824</th>\n",
       "      <td>Stone In My Shoe</td>\n",
       "      <td>Rudolf Schenker lyric Klaus Meine I dancin try...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Scorpions</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40499</th>\n",
       "      <td>TIN SOLDIER</td>\n",
       "      <td>I little that want jump you oh look a pass sky...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Uriah Heep</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32051</th>\n",
       "      <td>I Am a Stone</td>\n",
       "      <td>it hard that I on straight you be it lung and ...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Demon Hunter</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34364</th>\n",
       "      <td>Too Much To Ask</td>\n",
       "      <td>it I feel lonely I wish cure it funny think go...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34056</th>\n",
       "      <td>With You in Mind</td>\n",
       "      <td>I so I think but love find these thing I I pic...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Marianne Faithfull</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      SName  \\\n",
       "2157                             Number One   \n",
       "3187   Put That Thang On U (ft. Snoop Dogg)   \n",
       "9164      The Resurrection of Scott Mescudi   \n",
       "2145                         Feel Like Home   \n",
       "6442       Public Service Announcement 2000   \n",
       "...                                     ...   \n",
       "31824                      Stone In My Shoe   \n",
       "40499                           TIN SOLDIER   \n",
       "32051                          I Am a Stone   \n",
       "34364                       Too Much To Ask   \n",
       "34056                      With You in Mind   \n",
       "\n",
       "                                                   Lyric    Genre  \\\n",
       "2157   uh uh uh I got to bring dirty thas you well wa...  Hip Hop   \n",
       "3187   Fala lady like lady Ne Yo sing to real quick I...  Hip Hop   \n",
       "9164              Instrumental once realize free you fly  Hip Hop   \n",
       "2145   these day dark night cold People act like lose...  Hip Hop   \n",
       "6442   this another public bring in by Slim Shady Emi...  Hip Hop   \n",
       "...                                                  ...      ...   \n",
       "31824  Rudolf Schenker lyric Klaus Meine I dancin try...     Rock   \n",
       "40499  I little that want jump you oh look a pass sky...     Rock   \n",
       "32051  it hard that I on straight you be it lung and ...     Rock   \n",
       "34364  it I feel lonely I wish cure it funny think go...     Rock   \n",
       "34056  I so I think but love find these thing I I pic...     Rock   \n",
       "\n",
       "                   Artist  lyric_length_processed  \n",
       "2157                Nelly                     299  \n",
       "3187                Ne-yo                     233  \n",
       "9164             Kid Cudi                       6  \n",
       "2145           Fort Minor                     239  \n",
       "6442               Eminem                      51  \n",
       "...                   ...                     ...  \n",
       "31824           Scorpions                     101  \n",
       "40499          Uriah Heep                      67  \n",
       "32051        Demon Hunter                     117  \n",
       "34364       Avril Lavigne                     130  \n",
       "34056  Marianne Faithfull                      39  \n",
       "\n",
       "[999 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54fbe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = LabelEncoder().fit_transform(df[\"Genre\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a7b4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "y = list(df['label'])\n",
    "x = list(df['Lyric'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.np_utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    print(one_hot)\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "\n",
    "x_enc = x\n",
    "y_enc = encode(le, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222df10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.asarray(x_enc), np.asarray(y_enc), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c51cc0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400001it [00:10, 39531.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {} # Will be a 100dim vector for each word in glove, found as embeddings_index[word]\n",
    "f = open('glove.6B.100d.txt',encoding='utf8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdeabc",
   "metadata": {},
   "source": [
    "## Defining hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8744b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = 30000\n",
    "MAX_LENGTH = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3cb62f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=VOCABULARY_SIZE)\n",
    "tokenizer.fit_on_texts(list(x_train) + list(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271ab1e",
   "metadata": {},
   "source": [
    "Turning tokens into lists of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ac9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_sequence = tokenizer.texts_to_sequences(x_train)\n",
    "xtest_sequence = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35168ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 500)\n"
     ]
    }
   ],
   "source": [
    "xtrain_padding = sequence.pad_sequences(xtrain_sequence, maxlen=MAX_LENGTH)\n",
    "xtest_padding = sequence.pad_sequences(xtest_sequence, maxlen=MAX_LENGTH)\n",
    "print(xtest_padding.shape)\n",
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fd4040e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8570 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8571, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8570/8570 [00:00<00:00, 517182.03it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 100))\n",
    "print(embedding_matrix.shape)\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001bcbe4",
   "metadata": {},
   "source": [
    "- Embedding_matrix is now just a matrix over the embeddings. i.e as embedding_index but in matrix form with 29000 ish rows\n",
    "- word_index is a mapping of all of the words appearing in lyrics to an integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5b993",
   "metadata": {},
   "source": [
    "## LSTM model with glove embeddings and two dense layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa50c82",
   "metadata": {},
   "source": [
    "We could change dropout percentage to further avoid/less avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d741a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                    100,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=MAX_LENGTH,\n",
    "                    trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.3, recurrent_dropout=0.3)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31cf032",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ytrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-43eb361224b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mytrain_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mytest_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ytrain' is not defined"
     ]
    }
   ],
   "source": [
    "#ytrain_encode = np_utils.to_categorical(ytrain)\n",
    "#ytest_encode = np_utils.to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23197cda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/1\n",
      "799/799 [==============================] - 67s 84ms/step - loss: 1.1012 - acc: 0.3442\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(xtrain_padding, \n",
    "                    y=y_train, \n",
    "                    batch_size=16, \n",
    "                    epochs=1, \n",
    "                    verbose=1)\n",
    "    predicts = model.predict(xtest_padding, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dd643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_preds))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy of ELMO is:\",accuracy_score(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bb132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_plots(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history[‘val_’+string])\n",
    "    plt.xlabel(“Epochs”)\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, ‘val_’+string])\n",
    "    plt.show()\n",
    "\n",
    "graph_plots(history, “accuracy”)\n",
    "graph_plots(history, “loss”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec6aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
